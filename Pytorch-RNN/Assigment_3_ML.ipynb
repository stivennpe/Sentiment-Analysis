{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assigment 3 ML.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install torchtext==0.10.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "UfRSnUpAYHG6",
        "outputId": "39ce7928-89b9-47ae-e810-bccbaede74d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchtext==0.10.0\n",
            "  Downloading torchtext-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 13.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (4.64.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (1.21.6)\n",
            "Collecting torch==1.9.0\n",
            "  Downloading torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 831.4 MB 2.6 kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchtext==0.10.0) (4.2.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (1.24.3)\n",
            "Installing collected packages: torch, torchtext\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.11.0+cu113\n",
            "    Uninstalling torch-1.11.0+cu113:\n",
            "      Successfully uninstalled torch-1.11.0+cu113\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.12.0\n",
            "    Uninstalling torchtext-0.12.0:\n",
            "      Successfully uninstalled torchtext-0.12.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.12.0+cu113 requires torch==1.11.0, but you have torch 1.9.0 which is incompatible.\n",
            "torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.9.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.9.0 torchtext-0.10.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchtext"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zvA5jRh5TMNt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.modules.activation import Sigmoid"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXWjpSf6jQlO",
        "outputId": "fb7b3593-4d4b-4c35-9f84-7ff382c73c7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#preprocessing\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize\n",
        "stopWords = set(stopwords.words('english'))"
      ],
      "metadata": {
        "id": "U_WKeG1pUjIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_whitespace(sentence):\n",
        "  return \" \".join(sentence.split())"
      ],
      "metadata": {
        "id": "C62s7DqKWc2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing(text):\n",
        "  clean_text= []\n",
        "  text= normalize_whitespace(text)\n",
        "  for t in text:\n",
        "    t = t.lower()\n",
        "    t= t.replace(\"<br /><br />\", \"\")\n",
        "    clean_text.append(t)\n",
        "  return clean_text"
      ],
      "metadata": {
        "id": "yaWliZQjw2Bo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchtext.legacy import data\n",
        "\n",
        "SEED = 42\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "TEXT = data.Field(tokenize = 'spacy',\n",
        "                  tokenizer_language = 'en_core_web_sm', stop_words = stopWords)\n",
        "LABEL = data.LabelField(dtype = torch.float)"
      ],
      "metadata": {
        "id": "C3OnHPfbrjS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fields = [('text', TEXT), ('label', LABEL)]\n",
        "\n",
        "train_data = data.TabularDataset(\n",
        "    path=\"/content/IMDB Dataset.csv\",\n",
        "    format='csv',\n",
        "    fields=fields,\n",
        "    skip_header= False,\n",
        ")"
      ],
      "metadata": {
        "id": "_i3Zb3tYubx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "train_data, test_data = train_data.split(split_ratio=0.7, random_state = random.seed(SEED))"
      ],
      "metadata": {
        "id": "8OBxQyJovR6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vars(train_data[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xdQPbn9vZZq",
        "outputId": "9b86160b-f746-4ee1-b8dc-e0094ee893a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': ['Harvey', 'Keital', \"'s\", 'best', 'performance', 'far', 'new', 'century', '.', 'Very', 'nicely', 'photographed', ',', 'beautiful', 'snap', '-', 'shot', 'pre', '-', 'Castro', 'Cuba', '.', 'The', 'story', 'revolves', 'around', 'nephew', 'local', 'minor', 'crime', 'boss', 'develops', 'friendship', 'American', 'Hollywood', 'connections', '.', 'It', \"'s\", 'really', 'moment', 'boy', 'awakens', 'fact', 'small', 'circle', 'people', 'knows', 'actually', 'live', 'much', 'larger', ',', 'much', 'complex', 'world', \"n't\", 'yet', 'understand.the', 'script', 'strong', 'filled', 'humor', ',', 'direction', 'crisp', '.', 'Over', ',', 'really', 'professional', 'job', 'fits', 'well', 'tradition', 'Latin', 'American', 'cinema', '.', 'The', 'one', 'weakness', 'decision', 'shoot', 'sync', '-', 'sound', 'English', 'rather', 'Spanish', '-', 'probably', 'improve', 'sales', 'US', '.', 'Unfortunately', ',', 'makes', 'film', 'little', 'less', 'convincing', '.', 'But', 'see', 'beyond', ',', 'find', 'heartfelt', 'trip', 'another', 'world', '.', 'Recommended', '.'], 'label': 'positive'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcUKCVlFyH0y",
        "outputId": "de1a813b-db54-4aa3-d839-ce6a996580d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: 35001\n",
            "Number of testing examples: 15000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#validation dataset\n",
        "\n",
        "import random\n",
        "\n",
        "train_data, valid_data = train_data.split(random_state = random.seed(42))"
      ],
      "metadata": {
        "id": "s4rhDgG6QYXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of validation examples: {len(valid_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "metadata": {
        "id": "F5n0HXcpcFA5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70faa7ce-5625-41b1-9d7f-798553b78bed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: 24501\n",
            "Number of validation examples: 10500\n",
            "Number of testing examples: 15000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Build vocab\n",
        "TEXT.build_vocab(train_data, max_size = 25_000)\n",
        "LABEL.build_vocab(train_data)"
      ],
      "metadata": {
        "id": "D7dXPJgKy3di"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(TEXT.vocab.itos[:14])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v47Y4FfV0O1y",
        "outputId": "502f3c1d-aae1-476d-866b-20622a830c5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<unk>', '<pad>', ',', '.', 'I', '\"', \"'s\", '-', '/><br', 'movie', 'film', 'The', '(', \"n't\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#to use the GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "eyOjyDbR4Yfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size = BATCH_SIZE, \n",
        "    device = device,\n",
        "    sort_key = lambda x: len(x.text),\n",
        "    sort_within_batch=True\n",
        "    )"
      ],
      "metadata": {
        "id": "0jrQfaUc1SbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model\n"
      ],
      "metadata": {
        "id": "tlAz46xN1rE_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Single layer NN.\n",
        "Only use the Embedding layer to convert to dense and an unique Linear Layer"
      ],
      "metadata": {
        "id": "r_eFdaCadYAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_DIM = len(TEXT.vocab) #size of the vocabulary\n",
        "EMBEDDING_DIM = 100 #size of dense vectors\n",
        "HIDDEN_DIM = 256 # size of hidden sates\n",
        "OUTPUT_DIM = 1 #number of classes\n",
        "DROPOUT = 0.5\n"
      ],
      "metadata": {
        "id": "eX1WHEVW6l35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "nRoC4CNwcJ9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Calculate accuracy\n",
        "\n",
        "def binary_accuracy(preds, y):\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds)) # Rounding predictions: 0.75 --> 1 0.4 --> 0\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "metadata": {
        "id": "oKjiBkc1-dCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train"
      ],
      "metadata": {
        "id": "NruAfqBn-Lq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    epoch_loss = 0\n",
        "    model.train() #Turn on the training mode\n",
        "    for batch in iterator:  \n",
        "        optimizer.zero_grad() #return gradients to 0 each batch\n",
        "        predictions = model(batch.text).squeeze(1) \n",
        "        loss = criterion(predictions, batch.label)\n",
        "        loss.backward()\n",
        "        optimizer.step() \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "metadata": {
        "id": "W69idwcm-LHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate"
      ],
      "metadata": {
        "id": "DKanH1Si_WZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    model.eval() #Turn on evaluation mode\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "          predictions = model(batch.text).squeeze(1) \n",
        "          loss = criterion(predictions, batch.label)\n",
        "          acc = binary_accuracy(predictions, batch.label)\n",
        "          epoch_loss += loss.item()\n",
        "          epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "metadata": {
        "id": "60Jn_BLV_YKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TEST\n"
      ],
      "metadata": {
        "id": "QBe3aXD-AWUL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "One Layer \n",
        "RNN and Linear\n",
        "Name: \"model2\" \n",
        "optimizer= \"Adam\"\n",
        "'''\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "class MultilayerPerceptron(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, dropout):\n",
        "        super(MultilayerPerceptron, self).__init__() #to call the functions in the superclass\n",
        "        self.input_size = input_dim \n",
        "        self.hidden_size = hidden_dim\n",
        "        self.emb_size= embedding_dim\n",
        "        self.output_size= output_dim\n",
        "        self.dropout= dropout\n",
        "        self.embedding= nn.Embedding(self.input_size, self.emb_size)\n",
        "        self.rnn= nn.RNN(self.emb_size, self.hidden_size)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        " \n",
        "        \n",
        "    def forward(self, text): \n",
        "        embedded = self.embedding(text)\n",
        "        output, hidden = self.rnn(embedded)\n",
        "        hidden= F.sigmoid(hidden)\n",
        "        hidden= self.fc(hidden.squeeze(0))\n",
        "        return hidden"
      ],
      "metadata": {
        "id": "KStJNVuPUgnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model2 = MultilayerPerceptron(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, DROPOUT)\n",
        "\n",
        "#Optimizer and loss functions\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss() #Calculate loss using binary cross entrophy\n",
        "optimizer2 = optim.Adam(model2.parameters())#optim.SGD(model.parameters(), lr = 0.01) #\n",
        "\n",
        "#Send model and loss to GPU\n",
        "\n",
        "model2 = model2.to(device)\n"
      ],
      "metadata": {
        "id": "cNgT9eeN71vw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Model after implementing \"Sequential\" :\"model2\"\n",
        "Adam optimizer\n",
        "With dropout\n",
        "'''\n",
        "N_EPOCHS = 5\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    train_loss = train(model2, train_iterator, optimizer2, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model2, valid_iterator, criterion)\n",
        "    \n",
        "    print('Training Loss: ', train_loss)\n",
        "    print('Validation Loss: ', valid_loss)"
      ],
      "metadata": {
        "id": "pUA-yW99Wy-E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "431677c8-484b-49b8-d1d6-a3efa0d007ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1944: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss:  0.25738182492729267\n",
            "Validation Loss:  0.2662168355602207\n",
            "Training Loss:  0.2533072130098044\n",
            "Validation Loss:  0.24980272433974526\n",
            "Training Loss:  0.25335908469114227\n",
            "Validation Loss:  0.2506401788104664\n",
            "Training Loss:  0.2522907587395636\n",
            "Validation Loss:  0.2507451344620098\n",
            "Training Loss:  0.25220233952874616\n",
            "Validation Loss:  0.2585072394573327\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = evaluate(model2, test_iterator, criterion)\n",
        "print('Loss: ', test_loss , ' Acc: ', test_acc*100,'%')"
      ],
      "metadata": {
        "id": "B3e8mbVyaQD9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c220ae9-e7f4-4f32-d7c8-82507daf3034"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1944: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:  0.25851642907933986  Acc:  50.25044327086591 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "It has two layers RNN and Linear and another Linear.\n",
        "Name: \"model\"\n",
        "Optimizer= \"Adam\"\n",
        "'''\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, dropout):\n",
        "        super().__init__() #to call the functions in the superclass\n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim) #Embedding layer to create dense vector instead of sparse matrix\n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim) \n",
        "        self.hidden_fc = nn.Linear(hidden_dim,hidden_dim)\n",
        "        self.out_fc = nn.Linear(hidden_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.sigmoid= nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, text):\n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "        output, hidden = self.rnn(embedded) \n",
        "        hidden = self.dropout(hidden[-1,:,:])\n",
        "        hidden= self.sigmoid(hidden)\n",
        "        #hidden= F.relu(hidden)  \n",
        "        hidden= self.sigmoid(hidden)\n",
        "        #hidden = F.relu(self.hidden_fc(hidden))\n",
        "        return self.out_fc(hidden)"
      ],
      "metadata": {
        "id": "3TVDYx4b1sPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, DROPOUT)\n",
        "optimizer = optim.Adam(model.parameters()) #to update parameters of the module\n",
        "criterion = nn.MSELoss()#nn.BCEWithLogitsLoss() #Calculate loss using binary cross entrophy\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "TQUYsrtrwO0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Model = \"model\"\n",
        "'''\n",
        "#without dropout\n",
        "N_EPOCHS = 5\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    train_loss = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    print('Training Loss: ', train_loss)\n",
        "    print('Validation Loss: ', valid_loss)"
      ],
      "metadata": {
        "id": "fQ479JU0SkG4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6b45dc6-d10d-44dc-e037-0467de973c4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss:  0.255820761733827\n",
            "Validation Loss:  0.24958872731887932\n",
            "Training Loss:  0.2550050773835369\n",
            "Validation Loss:  0.2502760166471655\n",
            "Training Loss:  0.25460219441599385\n",
            "Validation Loss:  0.2530812394438368\n",
            "Training Loss:  0.2544392233339987\n",
            "Validation Loss:  0.25091444949309033\n",
            "Training Loss:  0.2549429510576607\n",
            "Validation Loss:  0.2497423057303284\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "print('Loss: ', test_loss , ' Acc: ', test_acc*100,'%')"
      ],
      "metadata": {
        "id": "MtmtSbgbi6M7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3635e6ae-0936-43fa-9039-04d96c7b5ed0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:  0.24972468075600077  Acc:  50.25044327086591 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Regular Machine Learning methods"
      ],
      "metadata": {
        "id": "RFJW_3fkOuPx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df= pd.read_csv(\"/content/IMDB Dataset.csv\")"
      ],
      "metadata": {
        "id": "2fUFnyaQP0PK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "3dL19QG-himC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "d6ce98dd-5cf3-4893-ef1f-80cd2dff4ca0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  review sentiment\n",
              "0      One of the other reviewers has mentioned that ...  positive\n",
              "1      A wonderful little production. <br /><br />The...  positive\n",
              "2      I thought this was a wonderful way to spend ti...  positive\n",
              "3      Basically there's a family where a little boy ...  negative\n",
              "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
              "...                                                  ...       ...\n",
              "49995  I thought this movie did a down right good job...  positive\n",
              "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
              "49997  I am a Catholic taught in parochial elementary...  negative\n",
              "49998  I'm going to have to disagree with the previou...  negative\n",
              "49999  No one expects the Star Trek movies to be high...  negative\n",
              "\n",
              "[50000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ce73ac4d-6340-43fa-a526-a69e483e9a0d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>I thought this movie did a down right good job...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>I am a Catholic taught in parochial elementary...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>I'm going to have to disagree with the previou...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>No one expects the Star Trek movies to be high...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ce73ac4d-6340-43fa-a526-a69e483e9a0d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ce73ac4d-6340-43fa-a526-a69e483e9a0d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ce73ac4d-6340-43fa-a526-a69e483e9a0d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Split Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "X = df[\"review\"]\n",
        "y = df['sentiment']\n",
        "    \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state = 40)"
      ],
      "metadata": {
        "id": "r9NcbhJXQLbY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Vectorization\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tf_en_vectorizer= TfidfVectorizer(stop_words=\"english\")\n",
        "\n",
        "X_train_features= tf_en_vectorizer.fit_transform(X_train)\n",
        "\n",
        "X_test_features= tf_en_vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "iEiaI8pMSnq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "clfs = {\n",
        "    \"RandomForest\":RandomForestClassifier(),\n",
        "    \"Logistic Regression\": LogisticRegression(),\n",
        "}\n",
        "for clf_name in clfs:\n",
        "  clf = clfs[clf_name]\n",
        "  clf.fit(X_train_features, y_train)\n",
        "  y_pred = clf.predict(X_test_features)\n",
        "  print(clf_name, accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "eFm59r-ySsgq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c79932f-45e5-42a0-8a14-408a3b261eb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForest 0.8556\n",
            "Logistic Regression 0.8912\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "confusion_matrix(y_test, y_pred)"
      ],
      "metadata": {
        "id": "s3mSHLR7TBiu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df58a90b-0311-4a4e-f27d-99000dfa4a88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4505,  595],\n",
              "       [ 493, 4407]])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    }
  ]
}